{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs2ETVGHmk6iCiJXotxCXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksm1560/cmcoding/blob/master/GPT%EC%BD%94%EB%94%A9_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#웹이란?\n",
        " - https://www.youtube.com/watch?v=yBPyzaccbkc"
      ],
      "metadata": {
        "id": "5vX-9yQHj6Ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HTML & CSS\n",
        " - https://www.w3schools.com/"
      ],
      "metadata": {
        "id": "u5efSbrFncYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#파이썬 웹 크롤링\n",
        " - 생성형 AI에게 파이썬 웹크롤링이 뭔지 개념에 대해 질문해보기"
      ],
      "metadata": {
        "id": "OBbqAvfnV2-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfq37zVqV2jV"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "웹 크롤링(Web scraping)은 인터넷 상에서 웹 페이지를 탐색하고, 필요한 정보를 수집하는 자동화된 프로세스를 말합니다.\n",
        "웹 크롤링은 보통 프로그램 또는 스크립트를 사용하여 웹 페이지의 내용을 추출하고, 그 정보를 분석하거나 저장하는 등의 작업에 활용됩니다.\n",
        "\n",
        "웹 크롤링의 기본적인 작동은 다음과 같습니다:\n",
        "\n",
        "1. URL 가져오기: 크롤링하려는 대상 웹 페이지의 URL을 결정합니다.\n",
        "2. HTTP 요청 보내기: 해당 URL로 HTTP 요청을 보내고, 웹 서버로부터 응답을 받습니다.\n",
        "3. 페이지 내용 분석: 받은 웹 페이지의 HTML 또는 다른 마크업 언어를 분석하여 필요한 데이터를 추출합니다.\n",
        "4. 데이터 가공 및 저장: 추출한 데이터를 필요에 따라 가공하거나 저장합니다.\n",
        "5. 웹 크롤링은 다양한 목적으로 사용됩니다. 일반적으로는 웹 사이트에서 데이터를 수집하여 분석하거나,\n",
        "특정 정보를 추출하여 다른 서비스에 제공하는 데 사용됩니다.\n",
        "그러나 웹 크롤링을 사용할 때는 항상 웹 사이트의 이용 약관을 확인하고,\n",
        "합법적인 수준에서 활용해야 합니다. 무분별한 크롤링은 웹 서버에 부하를 일으키고,\n",
        "웹 사이트 운영자에게 불편함을 주기 때문에 주의가 필요합니다.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - 웹 크롤링을 하는 이유는 무엇일까?"
      ],
      "metadata": {
        "id": "ttbS3zC9XOIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "웹 크롤링은 다양한 이유로 수행됩니다. 몇 가지 주요한 이유는 다음과 같습니다:\n",
        "\n",
        "1. 데이터 수집: 웹 크롤링은 웹 상의 다양한 웹 페이지에서 정보를 수집하는 데 사용됩니다.\n",
        "예를 들어, 가격 비교, 제품 리뷰, 뉴스 기사, 채용 정보 등을 수집할 수 있습니다.\n",
        "\n",
        "2. 경쟁 정보 수집: 기업은 경쟁사의 가격, 제품 정보, 마케팅 전략 등을 파악하기 위해 웹 크롤링을 사용할 수 있습니다.\n",
        "\n",
        "3. SEO 최적화: 웹 사이트 운영자들은 검색 엔진 최적화 (SEO)를 위해 웹 페이지의 키워드, 메타데이터, 백링크 등을 분석하기 위해 웹 크롤링을 수행합니다.\n",
        "\n",
        "4. 텍스트 및 자연어 처리 연구: 텍스트 데이터를 수집하여 자연어 처리 및 텍스트 마이닝 연구에 활용할 수 있습니다.\n",
        "감성 분석, 토픽 모델링 등의 분야에서 사용될 수 있습니다.\n",
        "\n",
        "5. 금융 분석: 금융 분석가들은 주가, 경제 지표, 금융 뉴스 등을 수집하여 시장 동향을 예측하는 데 웹 크롤링을 사용합니다.\n",
        "\n",
        "6. 소셜 미디어 분석: 소셜 미디어 플랫폼에서 사용자의 의견, 트렌드, 인기 있는 주제 등을 수집하여 분석할 수 있습니다.\n",
        "\n",
        "7. 업무 자동화: 일상적이고 반복적인 작업을 자동화하기 위해 웹 크롤링이 사용될 수 있습니다. 예를 들어,\n",
        "블로그에서 새로운 글을 검색하거나, 특정 웹 페이지의 변경을 모니터링하는 등의 작업을 자동으로 처리할 수 있습니다.\n",
        "\n",
        "그러나 웹 크롤링을 할 때는 항상 윤리적인 측면과 법적인 측면을 고려해야 합니다. 웹 사이트의 이용 약관을 확인하고,\n",
        "크롤링이 허용되는지 여부를 확인하는 것이 중요합니다. 부적절한 크롤링은 법적인 문제를 일으킬 수 있습니다.\n",
        "'''"
      ],
      "metadata": {
        "id": "sjZDrlyyXRJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#웹크롤링 이해하기\n",
        " - https://wikidocs.net/135794"
      ],
      "metadata": {
        "id": "0JEbpWIZfesm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#웹크롤링 해보기\n",
        "  - 뉴스 제목 크롤링하기\n",
        "   - 크롤링이 필요한 주소로 이동합니다.\n",
        "   - https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=%EC%98%A4%ED%94%88AI\n",
        "   - 타이틀 오른쪽 클릭 검사 누르기 또는 웹사이트의 코드 분석 (F12) 개발자모드\n",
        "   - 클래스 이름찾기"
      ],
      "metadata": {
        "id": "NMoRGxroX_1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WkhPrETYGTS",
        "outputId": "e76197b4-e375-4fa6-f734-77dbdaa8377a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 크롤링할 URL\n",
        "url = \"https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=%EC%98%A4%ED%94%88AI\"\n",
        "\n",
        "# HTTP GET 요청\n",
        "response = requests.get(url)\n",
        "a = []\n",
        "# 응답이 정상적인지 확인\n",
        "if response.status_code == 200:\n",
        "    # BeautifulSoup을 사용하여 HTML 파싱\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # 게시글 제목을 담고 있는 요소를 찾기\n",
        "    news_titles = soup.select('.news_tit')\n",
        "\n",
        "    # 각 제목 출력\n",
        "    for title in news_titles:\n",
        "        print(title.text)\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgJaYlGUZr5G",
        "outputId": "d37b3845-8e98-4b28-fa52-08922d52a705"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - https://www.yes24.com/Product/Search?domain=ALL&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5\n",
        "이 사이트에서 책 제목과 금액을 크롤링하려고해.\n",
        "책 제목은 gd_name 클래스, 가격은 yes_b 클래스에 있어\n",
        "파이썬 코드 작성해줘."
      ],
      "metadata": {
        "id": "WMTAhWEwfC1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 크롤링할 URL\n",
        "url = \"https://www.yes24.com/Product/Search?domain=ALL&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5\"\n",
        "\n",
        "# HTTP GET 요청\n",
        "response = requests.get(url)\n",
        "\n",
        "# 응답이 정상적인지 확인\n",
        "if response.status_code == 200:\n",
        "    # BeautifulSoup을 사용하여 HTML 파싱\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # 책 제목과 가격을 담고 있는 요소를 찾기\n",
        "    book_titles = soup.select('.gd_name')\n",
        "    book_prices = soup.select('.yes_b')\n",
        "\n",
        "    # 결과 출력\n",
        "    for title, price in zip(book_titles, book_prices):\n",
        "        print(\"책 제목:\", title.text.strip())\n",
        "        print(\"가격:\", price.text.strip())\n",
        "        print(\"=\"*50)\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v6WN0Gadz5o",
        "outputId": "744a0d38-3cf4-42af-b084-27a3ffc82825"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "책 제목: 챗GPT 교사 마스터 플랜\n",
            "가격: 21,600\n",
            "==================================================\n",
            "책 제목: 휴먼 클라우드\n",
            "가격: 10.0\n",
            "==================================================\n",
            "책 제목: 알아두면 평생 써먹는 인공지능(AI) 그림 수업\n",
            "가격: 3,240\n",
            "==================================================\n",
            "책 제목: GPT-4, ChatGPT, 라마인덱스, 랭체인을 활용한 인공지능 프로그래밍\n",
            "가격: 9.5\n",
            "==================================================\n",
            "책 제목: 혼자 공부하는 머신러닝+딥러닝\n",
            "가격: 15,300\n",
            "==================================================\n",
            "책 제목: 세계미래보고서 2024-2034\n",
            "가격: 10.0\n",
            "==================================================\n",
            "책 제목: 프롬프트 엔지니어링으로 인공지능 제대로 일 시키기\n",
            "가격: 25,200\n",
            "==================================================\n",
            "책 제목: 만들면서 배우는 40개의 엔트리 게임 + 인공지능 게임\n",
            "가격: 23,400\n",
            "==================================================\n",
            "책 제목: 된다! 생성형 AI 사진 & 이미지 만들기\n",
            "가격: 9.7\n",
            "==================================================\n",
            "책 제목: 비전공자도 이해할 수 있는 AI 지식\n",
            "가격: 17,550\n",
            "==================================================\n",
            "책 제목: 생성형 AI를 활용한 인공지능 아트\n",
            "가격: 19,800\n",
            "==================================================\n",
            "책 제목: 인공지능 활용교육\n",
            "가격: 9.5\n",
            "==================================================\n",
            "책 제목: AI 판타시티\n",
            "가격: 15,930\n",
            "==================================================\n",
            "책 제목: 인공지능을 위한 머신러닝과 딥러닝 with 파이썬\n",
            "가격: 9.9\n",
            "==================================================\n",
            "책 제목: 수학 지능\n",
            "가격: 16,200\n",
            "==================================================\n",
            "책 제목: 인공지능, 플랫폼, 노동의 미래\n",
            "가격: 10.0\n",
            "==================================================\n",
            "책 제목: 만화로 배우는 AI 인공지능\n",
            "가격: 17,820\n",
            "==================================================\n",
            "책 제목: 비즈니스모델 사용설명서\n",
            "가격: 9.0\n",
            "==================================================\n",
            "책 제목: 미래 세대를 위한 인공지능 이야기\n",
            "가격: 27,000\n",
            "==================================================\n",
            "책 제목: AI 시대 챗GPT 리터러시를 만나다\n",
            "가격: 18,000\n",
            "==================================================\n",
            "책 제목: 초·중·고 디지털 새싹을 위한 인공지능윤리\n",
            "가격: 9.4\n",
            "==================================================\n",
            "책 제목: 알쏭달쏭 인공지능과 PPT 마법사\n",
            "가격: 12,600\n",
            "==================================================\n",
            "책 제목: 최강의 AI 공쌤반 아이들\n",
            "가격: 10.0\n",
            "==================================================\n",
            "책 제목: MBTI 진로탐색\n",
            "가격: 28,000\n",
            "==================================================\n",
            "책 제목: 휴먼 클라우드\n",
            "가격: 18,000\n",
            "==================================================\n",
            "책 제목: 혼자 공부하는 머신러닝+딥러닝\n",
            "가격: 9.4\n",
            "==================================================\n",
            "책 제목: 나는 오렌지로 데이터 분석한다\n",
            "가격: 18,000\n",
            "==================================================\n",
            "책 제목: 비전공자도 이해할 수 있는 AI 지식\n",
            "가격: 15,120\n",
            "==================================================\n",
            "책 제목: 4차산업혁명 직업 시리즈 - AI 인공지능 미래직업카드\n",
            "가격: 17,640\n",
            "==================================================\n",
            "책 제목: 만들면서 배우는 파이썬과 40개의 작품들\n",
            "가격: 9.7\n",
            "==================================================\n",
            "책 제목: 십 대가 알아야 할 인공지능과 4차 산업혁명의 미래\n",
            "가격: 14,250\n",
            "==================================================\n",
            "책 제목: 인공지능을 위한 수학\n",
            "가격: 20,000\n",
            "==================================================\n",
            "책 제목: 인공지능 융합수업 가이드 (작곡 음악 국악)\n",
            "가격: 9.8\n",
            "==================================================\n",
            "책 제목: 만들면서 배우는 인공지능 엔트리와 40개의 작품들\n",
            "가격: 10,000\n",
            "==================================================\n",
            "책 제목: 미래 인공지능으로 황제재벌기\n",
            "가격: 13,500\n",
            "==================================================\n",
            "책 제목: 경기필 청소년음악회〈모차르트 vs 인공지능〉 - 수원\n",
            "가격: 19,800\n",
            "==================================================\n",
            "책 제목: [도서] 인터워크 인공지능 시리즈\n",
            "가격: 10.0\n",
            "==================================================\n",
            "책 제목: [eBook] 내 인공지능이 마왕이 되었다\n",
            "가격: 12,820\n",
            "==================================================\n",
            "책 제목: [eBook] 내 머릿속 인공지능\n",
            "가격: 3,240\n",
            "==================================================\n",
            "책 제목: [도서] 개념과 원리가 보이는 우리학교 인공지능 수업\n",
            "가격: 14,200\n",
            "==================================================\n",
            "책 제목: [도서] 주식회사 지구문화-초인수(초등 인공지능 수학)\n",
            "가격: 16,900\n",
            "==================================================\n",
            "책 제목: [eBook] 인공지능으로 재벌가 입성\n",
            "가격: 24,800\n",
            "==================================================\n",
            "책 제목: [도서] 교과서 수학으로 배우는 인공지능\n",
            "가격: 12,500\n",
            "==================================================\n",
            "책 제목: [eBook] 돌아온 인공지능으로 재벌인생!\n",
            "가격: 18,000\n",
            "==================================================\n",
            "책 제목: [eBook] 인공지능과 바이오로 탄생한 출동! BT걸\n",
            "가격: 10,000\n",
            "==================================================\n",
            "책 제목: [도서] SAPI(서울대 인공지능정책 이니셔티브) 연구총서\n",
            "가격: 17,820\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - 위 내용을 엑셀파일로 저장하는 코드 작성해줘."
      ],
      "metadata": {
        "id": "LCBT6SZ_e9pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# 크롤링할 URL\n",
        "url = \"https://www.yes24.com/Product/Search?domain=ALL&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5\"\n",
        "\n",
        "# HTTP GET 요청\n",
        "response = requests.get(url)\n",
        "\n",
        "# 응답이 정상적인지 확인\n",
        "if response.status_code == 200:\n",
        "    # BeautifulSoup을 사용하여 HTML 파싱\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # 책 제목과 가격을 담고 있는 요소를 찾기\n",
        "    book_titles = soup.select('.gd_name')\n",
        "    book_prices = soup.select('.yes_b')\n",
        "\n",
        "    # 데이터를 담을 리스트 초기화\n",
        "    data = []\n",
        "\n",
        "    # 결과를 리스트에 추가\n",
        "    for title, price in zip(book_titles, book_prices):\n",
        "        data.append({\n",
        "            '책 제목': title.text.strip(),\n",
        "            '가격': price.text.strip()\n",
        "        })\n",
        "\n",
        "    # 리스트를 데이터프레임으로 변환\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 데이터프레임을 엑셀 파일로 저장\n",
        "    df.to_excel('book_data.xlsx', index=False)\n",
        "\n",
        "    print(\"엑셀 파일로 저장되었습니다.\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIPOMFHGeoi8",
        "outputId": "20f632a8-13e8-4e0f-c887-5b1b9114dc5a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "엑셀 파일로 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#실습더하기\n",
        " - https://wikidocs.net/35949"
      ],
      "metadata": {
        "id": "RbqmJsCUhpea"
      }
    }
  ]
}